{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"89fa1a8ebec248a6aa5b5f2bc295f94e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_680a285289dd403997a3d4acb750c644","IPY_MODEL_82234ef3b2fe4bbcb6c3af4d5aba5bad","IPY_MODEL_9daf3d4ba1d54176a3a757e4650de96a"],"layout":"IPY_MODEL_42877f3dc15b4f74929dfddfdcef8f97"}},"680a285289dd403997a3d4acb750c644":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17c8a51ba69d4256a64cca7940b52f03","placeholder":"​","style":"IPY_MODEL_50521dd60d0a46878a9cc331bc048458","value":"config.json: 100%"}},"82234ef3b2fe4bbcb6c3af4d5aba5bad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddeb32e25fb04e10b725acd487a255bb","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4e0a7cd7e3641cc81eb5dad86a903a0","value":483}},"9daf3d4ba1d54176a3a757e4650de96a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fa7175765b84e3e8b931924597889ef","placeholder":"​","style":"IPY_MODEL_c3118f3f58b7437db465716cbde9a8c8","value":" 483/483 [00:00&lt;00:00, 7.92kB/s]"}},"42877f3dc15b4f74929dfddfdcef8f97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17c8a51ba69d4256a64cca7940b52f03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50521dd60d0a46878a9cc331bc048458":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddeb32e25fb04e10b725acd487a255bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4e0a7cd7e3641cc81eb5dad86a903a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fa7175765b84e3e8b931924597889ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3118f3f58b7437db465716cbde9a8c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ddfc6b6168a4123a21c8729731a243a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1a9907846a648cf89e0a01e4275647a","IPY_MODEL_77f0ac065a9f471cabcb14474bf43d58","IPY_MODEL_5b45c19c29a245ab8bfd56640eb3046b"],"layout":"IPY_MODEL_7d20eccff2fd48efa79d102f847dce38"}},"f1a9907846a648cf89e0a01e4275647a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8398ebf03b574a3bb28134f39f77db8c","placeholder":"​","style":"IPY_MODEL_003ada9335144566be43be880106ef92","value":"model.safetensors: 100%"}},"77f0ac065a9f471cabcb14474bf43d58":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfddd3f4e35545e8a81ab1c4d1f77d6e","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6af1a48cbb944487bb3245e9a5d37656","value":267954768}},"5b45c19c29a245ab8bfd56640eb3046b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_660e3f7723e74549a6c85a7edfaa92b3","placeholder":"​","style":"IPY_MODEL_62439cdef08b40268ab8ad6fcad85edd","value":" 268M/268M [00:02&lt;00:00, 121MB/s]"}},"7d20eccff2fd48efa79d102f847dce38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8398ebf03b574a3bb28134f39f77db8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"003ada9335144566be43be880106ef92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfddd3f4e35545e8a81ab1c4d1f77d6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af1a48cbb944487bb3245e9a5d37656":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"660e3f7723e74549a6c85a7edfaa92b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62439cdef08b40268ab8ad6fcad85edd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7693180,"sourceType":"datasetVersion","datasetId":4489940},{"sourceId":7693207,"sourceType":"datasetVersion","datasetId":4489962}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport torch\nfrom torch.optim import AdamW\nimport time","metadata":{"id":"Q21Am4Vusv_e","execution":{"iopub.status.busy":"2024-02-24T19:28:51.071813Z","iopub.execute_input":"2024-02-24T19:28:51.072472Z","iopub.status.idle":"2024-02-24T19:28:51.077632Z","shell.execute_reply.started":"2024-02-24T19:28:51.072440Z","shell.execute_reply":"2024-02-24T19:28:51.076654Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Untrained model:","metadata":{"id":"HBJNUXmfsv_h"}},{"cell_type":"code","source":"# Load the model\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\nmodel = model.to('cuda')  # if GPU is available\n\n# Load validation data\nval_data = pd.read_csv('/kaggle/input/test-data/test.csv')\nval_texts = val_data['review'].tolist()\nval_labels = val_data['sentiment'].map({'positive': 1, 'negative': 0}).tolist()\n\n# Initialize tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Tokenize data\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n\n# Create torch dataset for validation\nclass ReviewDataset(Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels:\n            item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\nval_dataset = ReviewDataset(val_encodings, val_labels)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n# Predict with the model\nmodel.eval()\npredictions = []\ntrue_labels = []\nfor batch in val_loader:\n    input_ids = batch['input_ids'].to('cuda')\n    attention_mask = batch['attention_mask'].to('cuda')\n    labels = batch['labels'].to('cuda')\n\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n\n    logits = outputs.logits\n    predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n    predictions.extend(predicted_labels)\n    true_labels.extend(labels.cpu().numpy())\n\n# Calculate metrics\naccuracy = accuracy_score(true_labels, predictions)\nf1 = f1_score(true_labels, predictions)\nconf_matrix = confusion_matrix(true_labels, predictions)\n\nprint(f'Accuracy: {accuracy}')\nprint(f'F1-score: {f1}')\nprint(f'Confusion matrix:\\n {conf_matrix}')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":596,"referenced_widgets":["89fa1a8ebec248a6aa5b5f2bc295f94e","680a285289dd403997a3d4acb750c644","82234ef3b2fe4bbcb6c3af4d5aba5bad","9daf3d4ba1d54176a3a757e4650de96a","42877f3dc15b4f74929dfddfdcef8f97","17c8a51ba69d4256a64cca7940b52f03","50521dd60d0a46878a9cc331bc048458","ddeb32e25fb04e10b725acd487a255bb","c4e0a7cd7e3641cc81eb5dad86a903a0","6fa7175765b84e3e8b931924597889ef","c3118f3f58b7437db465716cbde9a8c8","8ddfc6b6168a4123a21c8729731a243a","f1a9907846a648cf89e0a01e4275647a","77f0ac065a9f471cabcb14474bf43d58","5b45c19c29a245ab8bfd56640eb3046b","7d20eccff2fd48efa79d102f847dce38","8398ebf03b574a3bb28134f39f77db8c","003ada9335144566be43be880106ef92","cfddd3f4e35545e8a81ab1c4d1f77d6e","6af1a48cbb944487bb3245e9a5d37656","660e3f7723e74549a6c85a7edfaa92b3","62439cdef08b40268ab8ad6fcad85edd"]},"id":"cUr4b9XQsv_j","outputId":"fc6fb6ae-5167-40bf-ae9b-3da2c9a093a4","execution":{"iopub.status.busy":"2024-02-24T19:28:51.079234Z","iopub.execute_input":"2024-02-24T19:28:51.079525Z","iopub.status.idle":"2024-02-24T19:37:36.292800Z","shell.execute_reply.started":"2024-02-24T19:28:51.079502Z","shell.execute_reply":"2024-02-24T19:37:36.291748Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"024894afb9904936a8fba7f57c700e7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a110680c69994c8784baee99e4b5fa05"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9658c902ef6341468cf22f7f4c17c10d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14bf2c01095844d4a2fd763efc72a919"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cf67270a3fa400dab9e1e1bea8ca10e"}},"metadata":{}},{"name":"stdout","text":"Accuracy: 0.50325\nF1-score: 0.6695493098287044\nConfusion matrix:\n [[    0  9935]\n [    0 10065]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Trained Model:","metadata":{"id":"z3mLmRvFsv_k"}},{"cell_type":"code","source":"# Record start time\nstart_time = time.time()\n\n# Load data\ntrain_data = pd.read_csv('/kaggle/input/train-dataset/train.csv')\ntest_data = pd.read_csv('/kaggle/input/test-data/test.csv')\n\ntrain_data['sentiment'] = train_data['sentiment'].map({'positive': 1, 'negative': 0})\ntrain_texts = train_data['review'].tolist()\ntrain_labels = train_data['sentiment'].tolist()\n\ntest_data['sentiment'] = test_data['sentiment'].map({'positive': 1, 'negative': 0})\nval_texts = test_data['review'].tolist()\nval_labels = test_data['sentiment'].tolist()\n\n#data = pd.read_csv('train.csv')\n#data['sentiment'] = data['sentiment'].map({'positive': 1, 'negative': 0})\n#reviews = data['review'].tolist()\n#labels = data['sentiment'].tolist()\n\n# Split data into training and validation sets\n#train_texts, val_texts, train_labels, val_labels = train_test_split(reviews, labels, test_size=0.2)\n\n# Initialize tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Tokenize data\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n\n# Create torch dataset\nclass ReviewDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create dataloaders\ntrain_dataset = ReviewDataset(train_encodings, train_labels)\nval_dataset = ReviewDataset(val_encodings, val_labels)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n# Initialize model\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\nmodel = model.to('cuda')  # if GPU is available\n\n# Initialize optimizer\noptimizer = AdamW(model.parameters(), lr=1e-5)\n\n# Training loop\nfor epoch in range(3):  # number of epochs\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to('cuda')\n        attention_mask = batch['attention_mask'].to('cuda')\n        labels = batch['labels'].to('cuda')\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n# Save the model\nmodel.save_pretrained('sentiment_model_DistilBERT')\n\n# Record end time\nend_time = time.time()\n\nprint(\"Time required to fine-tune: \", end_time - start_time)","metadata":{"id":"RV_ZSu-wsv_k","execution":{"iopub.status.busy":"2024-02-24T19:37:36.295168Z","iopub.execute_input":"2024-02-24T19:37:36.295635Z","iopub.status.idle":"2024-02-24T20:55:27.523598Z","shell.execute_reply.started":"2024-02-24T19:37:36.295595Z","shell.execute_reply":"2024-02-24T20:55:27.522571Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Time required to fine-tune:  4671.2118899822235\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DistilBertTokenizerFast","metadata":{"execution":{"iopub.status.busy":"2024-02-24T20:58:32.479022Z","iopub.execute_input":"2024-02-24T20:58:32.479385Z","iopub.status.idle":"2024-02-24T20:58:32.487595Z","shell.execute_reply.started":"2024-02-24T20:58:32.479357Z","shell.execute_reply":"2024-02-24T20:58:32.486729Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load the model\nmodel = DistilBertForSequenceClassification.from_pretrained('sentiment_model_DistilBERT')\nmodel = model.to('cuda')  # if GPU is available\n\n# Load validation data\nval_data = pd.read_csv('/kaggle/input/test-data/test.csv')\nval_texts = val_data['review'].tolist()\nval_labels = val_data['sentiment'].map({'positive': 1, 'negative': 0}).tolist()  # convert sentiment to numeric\n\n# Initialize tokenizer\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n\n# Tokenize data\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n\n# Create torch dataset for validation\nclass ReviewDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\nval_dataset = ReviewDataset(val_encodings, val_labels)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n# Evaluate the model\nmodel.eval()\npredictions = []\ntrue_labels = []\nfor batch in val_loader:\n    input_ids = batch['input_ids'].to('cuda')\n    attention_mask = batch['attention_mask'].to('cuda')\n    labels = batch['labels'].to('cuda')\n\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n\n    logits = outputs.logits\n    predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n    predictions.extend(predicted_labels)\n    true_labels.extend(labels.cpu().numpy())\n\n# Calculate metrics\naccuracy = accuracy_score(true_labels, predictions)\nf1 = f1_score(true_labels, predictions)\nconf_matrix = confusion_matrix(true_labels, predictions)\n\nprint(f'Accuracy: {accuracy}')\nprint(f'F1-score: {f1}')\nprint(f'Confusion matrix:\\n {conf_matrix}')","metadata":{"id":"t3__sWl5sv_l","execution":{"iopub.status.busy":"2024-02-24T20:58:36.798948Z","iopub.execute_input":"2024-02-24T20:58:36.799269Z","iopub.status.idle":"2024-02-24T21:04:36.112930Z","shell.execute_reply.started":"2024-02-24T20:58:36.799244Z","shell.execute_reply":"2024-02-24T21:04:36.111974Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Accuracy: 0.9308\nF1-score: 0.9327894327894327\nConfusion matrix:\n [[9012  923]\n [ 461 9604]]\n","output_type":"stream"}]}]}